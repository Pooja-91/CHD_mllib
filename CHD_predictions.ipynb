{"cells":[{"cell_type":"code","source":["#/FileStore/tables/8norpmcw1472208802508/SAheart.csv\n"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":["###Read the data from csv file"],"metadata":{}},{"cell_type":"code","source":["HeartDF = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferSchema='true').load('/FileStore/tables/8norpmcw1472208802508/SAheart.csv')\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["HeartDF.show(4)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["###Findout relationship between family history and coronary heart disease"],"metadata":{}},{"cell_type":"code","source":["chd_count = HeartDF.groupBy( 'famhist', 'chd' ).count()\n\nchd_count.show()\n\nchd_count_pd = chd_count.toPandas()\nchd_count_pd"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["import matplotlib.pyplot as plt #sets up plotting under plt\nimport seaborn as sn            #sets up styles and gives us more plotting options\n\n\nfig = plt.figure(figsize=(10, 8))\n\n#plt.show()\nsn.barplot( y='count',x = 'famhist',hue = 'chd',data = chd_count_pd )\n\nplt.close()\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":["Observation: Family history increases the chances of having coronary disease"],"metadata":{}},{"cell_type":"markdown","source":["###Finding relationship between alcohol consumption and coronary heart disease"],"metadata":{}},{"cell_type":"code","source":["chd_alcohol_pd = HeartDF.select( HeartDF['alcohol'],HeartDF['chd']).toPandas()\nchd_alcohol_pd.head()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# distplot is used to worked with single variable data for distributions\n\nfig_ac =plt.figure(figsize=(10, 8))\n\nsn.distplot( chd_alcohol_pd[chd_alcohol_pd.chd == 1].alcohol,\n          hist = False,\n          color = 'r' )\n\nsn.distplot( chd_alcohol_pd[chd_alcohol_pd.chd == 0].alcohol,\n          hist = False,\n          color = 'g' )\ndisplay(fig_ac)\nplt.close()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["Observation: Alcohol consumption does not seem to be a differentiating factor between people who has coronary disease and not having coronary disease."],"metadata":{}},{"cell_type":"markdown","source":["####Relationship between age and coronary heart disease"],"metadata":{}},{"cell_type":"code","source":["#Relationship between age and coronary heart disease\n\nchd_age_pd = HeartDF.select( HeartDF['age'], HeartDF['chd'] ).toPandas()\n\nfig_agc = plt.figure(figsize=(10, 8))\n\nsn.distplot( chd_age_pd[chd_age_pd.chd == 1].age,\n          hist = False, color = 'r' )\n\nsn.distplot( chd_age_pd[chd_age_pd.chd == 0].age,\n          hist = False, color = 'b' )\ndisplay(fig_agc)\nplt.close()         \n"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["Observation: Age seems to be a differentiating factor between people who has coronary disease and not having coronary disease"],"metadata":{}},{"cell_type":"markdown","source":["####Find correations between variables"],"metadata":{}},{"cell_type":"code","source":["#Draw scatterplots for joint relationships and histograms for univariate distributions\n\nchd_pair_pd = HeartDF.select( HeartDF['age'],\n                          HeartDF['sbp'],\n                          HeartDF['obesity'],\n                          HeartDF['ldl'] ).toPandas()\n\n\n#f = plt.figure(figsize=(10,8))\nfig_ex = plt.figure(figsize=(10, 8))\nsn.pairplot(data=chd_pair_pd)\n\nfig_ex.savefig(\"sns_pair_plot.png\")\ndisplay(fig_ex)\nplt.close()\n"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["###Find relationship between obesity and ldl"],"metadata":{}},{"cell_type":"code","source":["# using regression line plots.\n\nfig_oidl = plt.figure(figsize=(10, 8))\n\nsn.regplot(y=\"ldl\", x=\"obesity\", data=chd_pair_pd)\n\ndisplay(fig_oidl)\nplt.close()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["\"Observation: There is a positive correlation between ldl and obesity\""],"metadata":{}},{"cell_type":"markdown","source":["####Drawing boxplots to understand distributions"],"metadata":{}},{"cell_type":"code","source":["chd_alh_tob_pd = HeartDF.select( HeartDF['alcohol'],\n                             HeartDF['tobacco'],\n                             HeartDF['chd'] ).toPandas()\nfig_box = plt.figure(figsize=(10, 8))\nsn.boxplot(y=\"alcohol\", x=\"chd\", data=chd_alh_tob_pd)\ndisplay(fig_box)\nplt.close()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["chd_alh_tob_pd = HeartDF.select( HeartDF['alcohol'],\n                             HeartDF['tobacco'],\n                             HeartDF['chd'] ).toPandas()\nfig_box2 = plt.figure(figsize=(10, 8))\nsn.boxplot(y=\"tobacco\", x=\"chd\", data=chd_alh_tob_pd)\n\ndisplay(fig_box2)\nplt.close()"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["#Calculating basic statistics\n\nfrom pyspark.mllib.stat import Statistics\nfrom pyspark.mllib.linalg import Vectors\nfrom pyspark.mllib.regression import LabeledPoint\n\n\ndef getVector( rec ):\n    return Vectors.dense(rec.alcohol, rec.tobacco,rec.age,rec.obesity,rec.ldl)\nchd_vec = HeartDF.rdd.map(lambda rec: getVector(rec))\n\nsummary = Statistics.colStats( chd_vec )\n\nprint (\" Mean of Summary {0}\".format(summary.mean()))\n\nprint (\" Variance of Summary {0}\".format(summary.variance()))"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["#Calcuating correlations\n\nimport numpy as np\n\nprint (\" np.sqrt of Summary {0}\".format(np.sqrt( summary.variance())))\n\nseriesX = HeartDF.select( HeartDF[\"obesity\"] )\nseriesY = HeartDF.select( HeartDF[\"ldl\"] )\n\nprint (\" seriesX : {0}\".format(seriesX))\n\n\ncorrelation = Statistics.corr(chd_vec, method=\"pearson\")\n\nprint (\"\\n correlation : {0}\".format(correlation))"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["####Creating vectors to represent multidimensional data"],"metadata":{}},{"cell_type":"code","source":["def parsePoint(rec):\n    return LabeledPoint( rec.chd, Vectors.dense(rec.alcohol,rec.tobacco,rec.age,rec.obesity,rec.ldl))\n\nchd_lp = HeartDF.rdd.map(lambda rec: parsePoint( rec ) )\n\nchd_lp.take(10)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["####Building a predictive model using Logistic Regression"],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.classification import LogisticRegressionWithLBFGS,LogisticRegressionModel\n\nmodel = LogisticRegressionWithLBFGS.train( chd_lp )"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["###Making predictions using the predictive model"],"metadata":{}},{"cell_type":"code","source":["labelsAndPreds = chd_lp.map(lambda lp: (lp.label,float(model.predict(lp.features))))\n\nprint \"predictions using the predictive model\"\nlabelsAndPreds.take( 10 )"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":["###Calculating the accuracy of the model"],"metadata":{}},{"cell_type":"code","source":["\n\ntotal_count = labelsAndPreds.count()\nsuccess_count = labelsAndPreds.filter(lambda rec: rec[0] == rec[1]).count()\nprint success_count,total_count\n\nprint(\"Successful prediction percentage: 0.71 \" + \n    str( round( success_count / total_count, 2 ) ) )"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":["####Adding more variables to the model prediction"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import OneHotEncoder, StringIndexer"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["###Encoding the categorical variable\n####Categorical variables can not be represented as continuous variables.\n####Categorical variables need to converted into binary representation, which is called one hot encoding."],"metadata":{}},{"cell_type":"code","source":["month_stringIndexer = StringIndexer(inputCol=\"famhist\",\n                                  outputCol=\"famhistIndex\")\n\nmonth_model = month_stringIndexer.fit(HeartDF)\n\nmonth_indexed = month_model.transform(HeartDF)\n\nmonth_encoder = OneHotEncoder(dropLast=False,\n                            inputCol=\"famhistIndex\",\n                            outputCol=\"famhistVec\")\n\ntraindata_final = month_encoder.transform(month_indexed)\n\ntraindata_final.show(10)"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":["###Combine all variables to create final vectors"],"metadata":{}},{"cell_type":"code","source":["def parseNewPoint(rec):\n  return LabeledPoint( rec.chd,\n          Vectors.dense(tuple( [rec.sbp,\n                              rec.tobacco,\n                              rec.ldl,\n                              rec.adiposity,\n                              rec.typea,\n                              rec.obesity,\n                              rec.alcohol,\n                              rec.age] +\n                              rec.famhistVec.toArray().tolist() ) ) )\n                              \nchd_lp_new = traindata_final.rdd.map( lambda rec: parseNewPoint( rec ) )\n\n\nchd_lp_new.take(10)"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["###Building the model and making predictions"],"metadata":{}},{"cell_type":"code","source":["model = LogisticRegressionWithLBFGS.train( chd_lp_new )\n\nlabelsAndPreds_new = chd_lp_new.map(lambda lp: ( lp.label,\n                                              float(model.predict(lp.features))))\n\nsuccess_count_new = labelsAndPreds_new.filter(lambda rec:\n                                            rec[0] == rec[1]).count()\n\nprint(\"Successful prediction percentage: 0.74 \" +\n    str( round( success_count_new / total_count, 2 ) ) )"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":["###Split the dataset into train & test\n#####Build the model using train dataset\n\n#####Test the model using test dataset\n\n#####Spark provides randomSplit() method on RDDs to split it randomly. The size of each split can be passed as an argument in terms of list.\n\n#####In the example below, train data set has 70% observations and test data set has only 30% of the observations."],"metadata":{}},{"cell_type":"code","source":["trainingData, testData = chd_lp_new.randomSplit( [0.7, 0.3] )\n\nmodel = LogisticRegressionWithLBFGS.train( trainingData )\n\nlabelsAndPreds_new = testData.map(lambda lp: ( lp.label,\n                                              float(model.predict(lp.features))))\n\nsuccess_count_new = labelsAndPreds_new.filter(lambda rec:\n                                            rec[0] == rec[1]).count()\n\nprint(\"Successful prediction percentage: 0.72 \" +\n    str( round( success_count_new / testData.count(), 2 ) ) )"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":["###Final\n\n######Create a confusion metrics to understand True positive rates and False Positive Rates"],"metadata":{}},{"cell_type":"code","source":["from sklearn import metrics\n\n\n#fig_heatmap = plt.figure(figsize=(10, 8))\nlabelsAndPreds_new_df = labelsAndPreds_new.toDF().toPandas()\ncm = metrics.confusion_matrix( labelsAndPreds_new_df._1, labelsAndPreds_new_df._2 )\n\nf = plt.figure(figsize=(10, 8))\n\nsn.heatmap(cm, annot=True, fmt='.2f' )\nplt.close()\ndisplay(f)\n\n"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":46}],"metadata":{"name":"CHD_predictions","notebookId":3250827959512035},"nbformat":4,"nbformat_minor":0}
